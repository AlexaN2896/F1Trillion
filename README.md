# MAE148SU24 Team-5 (F1 Trillion) Winter 2023 Repository
Project Goal:
The original goal was to use AI object detection paired with the OAK-D camera to build a model that recognizes basic street signs and color images from the camera. Based on how the AI model classifies these different objects and colors, the AI would then tell the autonomous car to react accordingly to the specific sign or color detected. The signs and colors would be placed on a track we planned, we would then pair the GNSS to set an origin on the track where the car would stop, start, and prevent the car from going out of bounds from our track. Additionally to using the camera and GNSS sensors, we wanted to include the Lidar to prevent the autonomous vehicle from running into objects, it was planned to prevent it from running into an object if an object was detected within a foot of it. 
Due to the limitations of time of taking MAE 148 during the summer, we had to change the goal of our project to using rock, paper, scissors to direct our car instead. With the new goal of our project, we still used an AI model and the OAK-D camera for object detection. We built a model that recognizes the hand signals rock, paper, scissors to control our autonomonous vehicle instead. 

Software and Hardware Description: 
